{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SHL_featuresExtraction_trial.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/farhanfuadabir/SHL2020/blob/master/SHL_featuresExtraction_trial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TivjRHwnc6d",
        "outputId": "dc7e60da-e98d-4f4c-a34e-5845933eeca7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W38YpHxMEdmj"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle as pk\n",
        "from scipy import signal,stats\n",
        "from scipy.special import entr\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZRqExW-4Psz"
      },
      "source": [
        "##Data **Import**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-unR5dTHE14F",
        "outputId": "a839c3d6-bdc3-4bf3-f68d-92f9a9134e7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "location = '/content/drive/My Drive/SHL Dataset 2020/challenge-2020-train-hand/'\n",
        "\n",
        "acc_x = pd.read_csv(location + 'Acc_x.txt', header = None, sep=\" \").to_numpy()\n",
        "print(\"Acc_x Import Done\")\n",
        "acc_y = pd.read_csv(location + 'Acc_y.txt', header = None, sep=\" \").to_numpy()\n",
        "print(\"Acc_y Import Done\")\n",
        "acc_z = pd.read_csv(location + 'Acc_z.txt', header = None, sep=\" \").to_numpy()\n",
        "print(\"Acc_z Import Done\")\n",
        "mag_x = pd.read_csv(location + 'Mag_x.txt', header = None, sep=\" \").to_numpy()\n",
        "print(\"Mag_x Import Done\")\n",
        "mag_y = pd.read_csv(location + 'Mag_y.txt', header = None, sep=\" \").to_numpy()\n",
        "print(\"Mag_y Import Done\")\n",
        "mag_z = pd.read_csv(location + 'Mag_z.txt', header = None, sep=\" \").to_numpy()\n",
        "print(\"Mag_z Import Done\")\n",
        "gyr_x = pd.read_csv(location + 'Gyr_x.txt', header = None, sep=\" \").to_numpy()\n",
        "print(\"Gyr_x Import Done\")\n",
        "gyr_y = pd.read_csv(location + 'Gyr_y.txt', header = None, sep=\" \").to_numpy()\n",
        "print(\"Gyr_y Import Done\")\n",
        "gyr_z = pd.read_csv(location + 'Gyr_z.txt', header = None, sep=\" \").to_numpy()\n",
        "print(\"Gyr_z Import Done\")\n",
        "pres = pd.read_csv(location + 'Pressure.txt', header = None, sep=\" \").to_numpy()\n",
        "print(\"Pressure Import Done\")\n",
        "\n",
        "y = pd.read_csv(location + 'Label.txt', header = None, sep=\" \").mode(axis=1).to_numpy().flatten()\n",
        "print(\"Label Import Done\")\n",
        "\n",
        "print(\"\\n\\nImport Completed\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acc_x Import Done\n",
            "Acc_y Import Done\n",
            "Acc_z Import Done\n",
            "Mag_x Import Done\n",
            "Mag_y Import Done\n",
            "Mag_z Import Done\n",
            "Gyr_x Import Done\n",
            "Gyr_y Import Done\n",
            "Gyr_z Import Done\n",
            "Pressure Import Done\n",
            "Label Import Done\n",
            "\n",
            "\n",
            "Import Completed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOIJGW-z4iHP"
      },
      "source": [
        "## Feature **Extraction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfg23EDKOfPn",
        "outputId": "28411404-135a-4a60-def9-5c6d914dbf2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "def magnitude(x,y,z):\n",
        "  return np.sqrt(x**2 + y**2 + z**2)\n",
        "\n",
        "def entrop(pk,axis=0):\n",
        "     pk = pk / np.sum(pk, axis=axis, keepdims=True)\n",
        "     vec = entr(pk)\n",
        "     S = np.sum(vec, axis=axis)\n",
        "     return S\n",
        "\n",
        "def autocorr(x,axis=0):\n",
        "    result = np.correlate(x, x, mode='full')\n",
        "    return result[result.size // 2:]\n",
        "\n",
        "\n",
        "# Magnitude Calculation\n",
        "acc_MAG = magnitude(acc_x,acc_y,acc_z)\n",
        "mag_MAG = magnitude(mag_x,mag_y,mag_z)\n",
        "gyr_MAG = magnitude(gyr_x,gyr_y,gyr_z)\n",
        "\n",
        "# Statistical Feature Calculation\n",
        "acc_mean = np.mean(acc_MAG,axis=1)\n",
        "acc_std = np.std(acc_MAG,axis=1)\n",
        "acc_max = np.max(acc_MAG,axis=1)\n",
        "acc_min = np.min(acc_MAG,axis=1)\n",
        "mag_mean = np.mean(mag_MAG,axis=1)\n",
        "mag_std = np.std(mag_MAG,axis=1)\n",
        "mag_max = np.max(mag_MAG,axis=1)\n",
        "mag_min = np.min(mag_MAG,axis=1)\n",
        "gyr_mean = np.mean(gyr_MAG,axis=1)\n",
        "gyr_std = np.std(gyr_MAG,axis=1)\n",
        "gyr_max = np.max(gyr_MAG,axis=1)\n",
        "gyr_min = np.min(gyr_MAG,axis=1)\n",
        "pres_mean = np.mean(pres,axis=1)\n",
        "pres_std = np.std(pres,axis=1)\n",
        "pres_max = np.max(pres,axis=1)\n",
        "pres_min = np.min(pres,axis=1)\n",
        "\n",
        "# Frequency Domain Feature Calculation\n",
        "fs = 100\n",
        "acc_FREQ,acc_PSD = signal.welch(acc_MAG,fs,nperseg=500,axis=1)\n",
        "mag_FREQ,mag_PSD = signal.welch(mag_MAG,fs,nperseg=500,axis=1)\n",
        "\n",
        "# Max PSD value\n",
        "acc_PSDmax = np.max(acc_PSD,axis=1)\n",
        "mag_PSDmax = np.max(mag_PSD,axis=1)\n",
        "\n",
        "# Frequency Entropy\n",
        "acc_entropy = entrop(acc_PSD,axis=1)\n",
        "mag_entropy = entrop(mag_PSD,axis=1)\n",
        "\n",
        "# Frequency Center\n",
        "acc_fc = np.sum((acc_FREQ*acc_PSD),axis=1) / np.sum(acc_PSD,axis=1)\n",
        "mag_fc = np.sum((mag_FREQ*mag_PSD),axis=1) / np.sum(mag_PSD,axis=1)\n",
        "\n",
        "# Autocorrelation Calculation\n",
        "acc_acr = np.apply_along_axis(autocorr,1,acc_MAG)\n",
        "print(acc_acr.shape)\n",
        "\n",
        "acc_features = np.stack((acc_mean,acc_std,acc_max,acc_min,acc_PSDmax,acc_entropy,acc_fc),axis=1)\n",
        "mag_features = np.stack((mag_mean,mag_std,mag_max,mag_min,mag_PSDmax,mag_entropy,mag_fc),axis=1)\n",
        "gyr_features = np.stack((gyr_mean,gyr_std,gyr_max,gyr_min),axis=1)\n",
        "pres_features = np.stack((pres_mean,pres_std,pres_max,pres_min),axis=1)\n",
        "\n",
        "X = np.concatenate([acc_features,mag_features,gyr_features,pres_features],axis=1)\n",
        "\n",
        "print(\"X shape: \",X.shape)\n",
        "print(\"y shape: \",y.shape)\n",
        "\n",
        "print(\"Feature Extraction Done\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-e6a7dd8f65f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Magnitude Calculation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0macc_MAG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmagnitude\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc_z\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mmag_MAG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmagnitude\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmag_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmag_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmag_z\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mgyr_MAG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmagnitude\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgyr_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgyr_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgyr_z\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'acc_x' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XN8l2lk49KH"
      },
      "source": [
        "## Training: **Decision Tree**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HM6yPJrMep-d",
        "outputId": "b1ec6ca1-8f64-4c80-bbfb-8a7bfb8ad5b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "#Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)\n",
        "\n",
        "dtree = DecisionTreeClassifier()\n",
        "dtree.fit(X_train, y_train)\n",
        "\n",
        "print(\"Decision Tree Training Done\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decision Tree Training Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PV2xxXLs3A9Q",
        "outputId": "804d0724-208c-4ade-b412-aa26ea7415da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "#Making Prediction\n",
        "y_pred = dtree.predict(X_test)\n",
        "\n",
        "#Evaluating Algorithm\n",
        "print(\"Confusion Matrix: \\n\\n\",confusion_matrix(y_test,y_pred))\n",
        "print(\"\\n\\nReport: \\n\\n\",classification_report(y_test,y_pred))\n",
        "print(\"Accuracy: \",accuracy_score(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix: \n",
            "\n",
            " [[1101   42    0   14   22   24   18    9]\n",
            " [  33  950    4   24    9   11   12    3]\n",
            " [   0    4   94    0    0    0    1    0]\n",
            " [   4   25    1  447    6    5    3    0]\n",
            " [  22    6    0    7  689   41   24    6]\n",
            " [  36   14    0   10   38  242   18    4]\n",
            " [  30   13    0    5   15   22  722   80]\n",
            " [  18    7    0    1    9    5   98  710]]\n",
            "\n",
            "\n",
            "Report: \n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.89      0.90      0.89      1230\n",
            "           2       0.90      0.91      0.90      1046\n",
            "           3       0.95      0.95      0.95        99\n",
            "           4       0.88      0.91      0.89       491\n",
            "           5       0.87      0.87      0.87       795\n",
            "           6       0.69      0.67      0.68       362\n",
            "           7       0.81      0.81      0.81       887\n",
            "           8       0.87      0.84      0.86       848\n",
            "\n",
            "    accuracy                           0.86      5758\n",
            "   macro avg       0.86      0.86      0.86      5758\n",
            "weighted avg       0.86      0.86      0.86      5758\n",
            "\n",
            "Accuracy:  0.8605418548106981\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbLkR2Zu4vCU"
      },
      "source": [
        "## Training: **SVM (linear)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4L26Xftlf5OQ"
      },
      "source": [
        "svmLin = SVC(kernel='linear',C=1)\n",
        "svmLin.fit(X_train, y_train)\n",
        "\n",
        "print(\"SVM_lin Training Done\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwXoCM0710AM"
      },
      "source": [
        "#Making Prediction\n",
        "y_pred = svmLin.predict(X_test)\n",
        "\n",
        "#Evaluating Algorithm\n",
        "print(\"Confusion Matrix: \\n\\n\",confusion_matrix(y_test,y_pred))\n",
        "print(\"\\n\\nReport: \\n\\n\",classification_report(y_test,y_pred))\n",
        "print(\"Accuracy: \",accuracy_score(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isAro6r145Ep"
      },
      "source": [
        "## Training: **SVM (poly)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDjj3MaJeHBx"
      },
      "source": [
        "svmPoly = SVC(kernel='poly', degree=8)\n",
        "svmPoly.fit(X_train, y_train)\n",
        "\n",
        "print(\"SVM_poly Training Done\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSWURU_G13oG"
      },
      "source": [
        "#Making Prediction\n",
        "y_pred = svmPoly.predict(X_test)\n",
        "\n",
        "#Evaluating Algorithm\n",
        "print(\"Confusion Matrix: \\n\\n\",confusion_matrix(y_test,y_pred))\n",
        "print(\"\\n\\nReport: \\n\\n\",classification_report(y_test,y_pred))\n",
        "print(\"Accuracy: \",accuracy_score(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tflQMGGp_V3p"
      },
      "source": [
        "##**2019** Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCTylD5N_XPI",
        "outputId": "a2eb70ec-2a85-435f-feed-3f8cf91c75d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "location = '/content/drive/My Drive/SHL Dataset 2019/Test/Hand/'\n",
        "\n",
        "acc_x = pd.read_csv(location + 'Acc_x.txt', header = None, sep=\" \").to_numpy()\n",
        "acc_y = pd.read_csv(location + 'Acc_y.txt', header = None, sep=\" \").to_numpy()\n",
        "acc_z = pd.read_csv(location + 'Acc_z.txt', header = None, sep=\" \").to_numpy()\n",
        "mag_x = pd.read_csv(location + 'Mag_x.txt', header = None, sep=\" \").to_numpy()\n",
        "mag_y = pd.read_csv(location + 'Mag_y.txt', header = None, sep=\" \").to_numpy()\n",
        "mag_z = pd.read_csv(location + 'Mag_z.txt', header = None, sep=\" \").to_numpy()\n",
        "gyr_x = pd.read_csv(location + 'Gyr_x.txt', header = None, sep=\" \").to_numpy()\n",
        "gyr_y = pd.read_csv(location + 'Gyr_y.txt', header = None, sep=\" \").to_numpy()\n",
        "gyr_z = pd.read_csv(location + 'Gyr_z.txt', header = None, sep=\" \").to_numpy()\n",
        "pres = pd.read_csv(location + 'Pressure.txt', header = None, sep=\" \").to_numpy()\n",
        "\n",
        "y_test = pd.read_csv(location + 'Label_test.txt', header = None, sep=\" \").to_numpy()\n",
        "y_test,_ = stats.mode(y_test,axis=1,nan_policy='omit')\n",
        "y_test = y_test.flatten()\n",
        "\n",
        "print(\"Import Completed\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Import Completed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yYn3Ebc_mEq",
        "outputId": "23d96ada-bd98-4fe2-e8ba-126705df6e36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "def magnitude(x,y,z):\n",
        "  return np.sqrt(x**2 + y**2 + z**2)\n",
        "\n",
        "def entrop(pk,axis=0):\n",
        "     pk = pk / np.sum(pk, axis=axis, keepdims=True)\n",
        "     vec = entr(pk)\n",
        "     S = np.sum(vec, axis=axis)\n",
        "     return S\n",
        "\n",
        "\n",
        "# Magnitude Calculation\n",
        "acc_MAG = magnitude(acc_x,acc_y,acc_z)\n",
        "mag_MAG = magnitude(mag_x,mag_y,mag_z)\n",
        "gyr_MAG = magnitude(gyr_x,gyr_y,gyr_z)\n",
        "\n",
        "# Statistical Feature Calculation\n",
        "acc_mean = np.mean(acc_MAG,axis=1)\n",
        "acc_std = np.std(acc_MAG,axis=1)\n",
        "acc_max = np.max(acc_MAG,axis=1)\n",
        "acc_min = np.min(acc_MAG,axis=1)\n",
        "mag_mean = np.mean(mag_MAG,axis=1)\n",
        "mag_std = np.std(mag_MAG,axis=1)\n",
        "mag_max = np.max(mag_MAG,axis=1)\n",
        "mag_min = np.min(mag_MAG,axis=1)\n",
        "gyr_mean = np.mean(gyr_MAG,axis=1)\n",
        "gyr_std = np.std(gyr_MAG,axis=1)\n",
        "gyr_max = np.max(gyr_MAG,axis=1)\n",
        "gyr_min = np.min(gyr_MAG,axis=1)\n",
        "pres_mean = np.mean(pres,axis=1)\n",
        "pres_std = np.std(pres,axis=1)\n",
        "pres_max = np.max(pres,axis=1)\n",
        "pres_min = np.min(pres,axis=1)\n",
        "\n",
        "# Frequency Domain Feature Calculation\n",
        "fs = 100\n",
        "acc_FREQ,acc_PSD = signal.welch(acc_MAG,fs,nperseg=500,axis=1)\n",
        "mag_FREQ,mag_PSD = signal.welch(mag_MAG,fs,nperseg=500,axis=1)\n",
        "\n",
        "# Max PSD value\n",
        "acc_PSDmax = np.max(acc_PSD,axis=1)\n",
        "mag_PSDmax = np.max(mag_PSD,axis=1)\n",
        "\n",
        "# Frequency Entropy\n",
        "acc_entropy = entrop(acc_PSD,axis=1)\n",
        "mag_entropy = entrop(mag_PSD,axis=1)\n",
        "\n",
        "# Frequency Center\n",
        "acc_fc = np.sum((acc_FREQ*acc_PSD),axis=1) / np.sum(acc_PSD,axis=1)\n",
        "mag_fc = np.sum((mag_FREQ*mag_PSD),axis=1) / np.sum(mag_PSD,axis=1)\n",
        "\n",
        "acc_features = np.stack((acc_mean,acc_std,acc_max,acc_min,acc_PSDmax,acc_entropy,acc_fc),axis=1)\n",
        "mag_features = np.stack((mag_mean,mag_std,mag_max,mag_min,mag_PSDmax,mag_entropy,mag_fc),axis=1)\n",
        "gyr_features = np.stack((gyr_mean,gyr_std,gyr_max,gyr_min),axis=1)\n",
        "pres_features = np.stack((pres_mean,pres_std,pres_max,pres_min),axis=1)\n",
        "\n",
        "X_test = np.concatenate([acc_features,mag_features,gyr_features,pres_features],axis=1)\n",
        "\n",
        "print(\"X shape: \",X.shape)\n",
        "print(\"y shape: \",y.shape)\n",
        "\n",
        "print(\"Feature Extraction Done\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X shape:  (28789, 22)\n",
            "y shape:  (28789,)\n",
            "Feature Extraction Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNJKY09zAChB",
        "outputId": "7bb9d54e-8c17-49b6-f0bc-1ec95cf0898c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "dtree = DecisionTreeClassifier()\n",
        "dtree.fit(X, y)\n",
        "\n",
        "print(\"Decision Tree Training Done\")\n",
        "\n",
        "#Making Prediction\n",
        "y_pred = dtree.predict(X_test)\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)\n",
        "\n",
        "#Evaluating Algorithm\n",
        "print(\"Confusion Matrix: \\n\\n\",confusion_matrix(y_test,y_pred))\n",
        "print(\"\\n\\nReport: \\n\\n\",classification_report(y_test,y_pred))\n",
        "print(\"Accuracy: \",accuracy_score(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decision Tree Training Done\n",
            "(28789, 22)\n",
            "(28789,)\n",
            "(55811, 22)\n",
            "(55811,)\n",
            "Confusion Matrix: \n",
            "\n",
            " [[6117  656   12  303 1540 2719  775  852]\n",
            " [ 340 4760  426 1166 1400  208  150  355]\n",
            " [   4  365 2788  384   20    0    2    1]\n",
            " [ 165 4173  269 1091  700  298   39  105]\n",
            " [ 586  482    8  333 3820 2110 1007 2989]\n",
            " [ 403  240    5   99 1015 1461  508 1810]\n",
            " [ 311  135    0   65  483  439 1421 2080]\n",
            " [  29   37    0    0    5    5   43 1699]]\n",
            "\n",
            "\n",
            "Report: \n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.77      0.47      0.58     12974\n",
            "           2       0.44      0.54      0.48      8805\n",
            "           3       0.79      0.78      0.79      3564\n",
            "           4       0.32      0.16      0.21      6840\n",
            "           5       0.43      0.34      0.38     11335\n",
            "           6       0.20      0.26      0.23      5541\n",
            "           7       0.36      0.29      0.32      4934\n",
            "           8       0.17      0.93      0.29      1818\n",
            "\n",
            "    accuracy                           0.41     55811\n",
            "   macro avg       0.43      0.47      0.41     55811\n",
            "weighted avg       0.48      0.41      0.43     55811\n",
            "\n",
            "Accuracy:  0.4149182060884055\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}